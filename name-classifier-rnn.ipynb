{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "name-classifier-rnn",
      "provenance": [],
      "authorship_tag": "ABX9TyMSt+H6nLPEzlKlZvbLn6Vd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jagr7/nlp-name-classifier/blob/master/name-classifier-rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be8m1uB3-1bT",
        "colab_type": "text"
      },
      "source": [
        "# NLP FROM SCRATCH: CLASSIFYING NAMES WITH A CHARACTER-LEVEL RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwoZBn1d9lT1",
        "colab_type": "text"
      },
      "source": [
        "# clone data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrvfWIHy9kgl",
        "colab_type": "code",
        "outputId": "66a40286-61e7-4068-b2cd-3630878f2a52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "!git clone https://github.com/jaybirrd/nlp_name_classifier.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nlp_name_classifier'...\n",
            "remote: Enumerating objects: 52, done.\u001b[K\n",
            "remote: Counting objects: 100% (52/52), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 52 (delta 8), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (52/52), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POgB41g0iqaC",
        "colab_type": "text"
      },
      "source": [
        "# prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGNSSRugx_3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import glob\n",
        "import os\n",
        "\n",
        "def find_files(path):\n",
        "  return glob.glob(path)\n",
        "\n",
        "#print(find_files('nlp_name_classifier/data/names/*.txt'))\n",
        "\n",
        "import unicodedata\n",
        "import string\n",
        "\n",
        "all_letters = string.ascii_letters + \" .,;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(\n",
        "      c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        and c in all_letters\n",
        "  )\n",
        "\n",
        "#print(unicode_to_ascii('Ślusàrski'))\n",
        "\n",
        "category_lines = {}\n",
        "all_categories = []\n",
        "\n",
        "def read_lines(filename):\n",
        "  lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
        "  return [unicode_to_ascii(line) for line in lines]\n",
        "\n",
        "#FUTURE DEV: put a popup here to select different datasets to analyze\n",
        "\n",
        "for filename in find_files('nlp_name_classifier/data/names/*.txt'):\n",
        "  category = os.path.splitext(os.path.basename(filename))[0]\n",
        "  all_categories.append(category)\n",
        "  lines = read_lines(filename)\n",
        "  category_lines[category] = lines\n",
        "\n",
        "n_categories = len(all_categories)\n",
        "\n",
        "#print(category_lines['Italian'][:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "126YpQL3G5Uy",
        "colab_type": "text"
      },
      "source": [
        "# turn names into tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZR2-ZRV8CBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "def letter_to_index(letter):\n",
        "  return all_letters.find(letter)\n",
        "\n",
        "#turn a letter into a <1 x n_letters> Tensor\n",
        "def letter_to_tensor(letter):\n",
        "  tensor = torch.zeros(1,n_letters)\n",
        "  tensor[0][letter_to_index(letter)] = 1\n",
        "  return tensor\n",
        "\n",
        "#turn lines into a <line length x 1 x n_letters> Tensor\n",
        "def line_to_tensor(line):\n",
        "  tensor = torch.zeros(len(line),1,n_letters)\n",
        "  for i, letter in enumerate(line):\n",
        "    tensor[i][0][letter_to_index(letter)] = 1\n",
        "    return tensor\n",
        "\n",
        "#print(line_to_tensor('James').size())\n",
        "#print(letter_to_tensor('J'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sws4a9Js-sYS",
        "colab_type": "text"
      },
      "source": [
        "# creating the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h0k_9ks-bxu",
        "colab_type": "code",
        "outputId": "6bb6dd2d-fbbe-4474-b673-e484f7e273a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "      super(RNN, self).__init__()\n",
        "      self.hidden_size = hidden_size\n",
        "      self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "      self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "      combined = torch.cat((input, hidden), dim=1)\n",
        "      hidden = self.i2h(combined)\n",
        "      output = self.softmax(self.i2o(combined))\n",
        "      return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "      return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "n_hidden = 128\n",
        "rnn = RNN(n_letters, n_hidden, n_categories)\n",
        "\n",
        "#FUTURE DEV: set up precomputing of tensors to further optimize\n",
        "\n",
        "input = line_to_tensor('Albert')\n",
        "hidden = torch.zeros(1, n_hidden)\n",
        "output, next_hidden = rnn(input[0], hidden)\n",
        "print(output, next_hidden)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-2.9126, -2.8580, -2.8921, -3.0047, -2.8901, -2.8264, -2.8996, -2.8903,\n",
            "         -2.9021, -2.9140, -2.8987, -2.9074, -2.8346, -3.0196, -2.8781, -2.8993,\n",
            "         -2.8394, -2.7860]], grad_fn=<LogSoftmaxBackward>) tensor([[ 0.0689,  0.0792,  0.0035, -0.0706, -0.0394,  0.0248, -0.0952, -0.0113,\n",
            "          0.1118,  0.0774,  0.0157,  0.0483, -0.1038,  0.0641, -0.0279,  0.0026,\n",
            "         -0.0588,  0.0736, -0.0022, -0.0117,  0.0119,  0.0232, -0.0739, -0.0377,\n",
            "         -0.0381,  0.0198, -0.0251, -0.0844, -0.0163,  0.1263,  0.0057, -0.0258,\n",
            "         -0.0249,  0.0275, -0.1024,  0.0699,  0.1249,  0.1092,  0.0124, -0.0347,\n",
            "         -0.0942, -0.0052,  0.0924, -0.0724,  0.1068, -0.0882, -0.0428,  0.0693,\n",
            "          0.0835,  0.0081, -0.0144,  0.0283, -0.0191, -0.0773, -0.0182,  0.0691,\n",
            "         -0.0493, -0.1274,  0.0900,  0.0489, -0.0414,  0.0372,  0.0447, -0.0258,\n",
            "          0.0674,  0.1139, -0.0748, -0.0215,  0.0244, -0.0410, -0.0438, -0.1023,\n",
            "         -0.0168, -0.0574,  0.1142, -0.0934,  0.0747,  0.0179,  0.1028,  0.1173,\n",
            "          0.0810,  0.1066, -0.0648,  0.0061, -0.0022,  0.0594, -0.0117,  0.0761,\n",
            "         -0.0567,  0.0033, -0.0431, -0.0686, -0.0337,  0.0023,  0.0574,  0.0340,\n",
            "         -0.0122, -0.1198,  0.0252, -0.0230, -0.0287, -0.0078,  0.0166, -0.0238,\n",
            "          0.0540,  0.0423, -0.0310,  0.0250,  0.0043,  0.0664,  0.0419, -0.0422,\n",
            "          0.0266,  0.1056,  0.0245,  0.0251, -0.0507,  0.1182,  0.0384,  0.1044,\n",
            "         -0.1206, -0.0120, -0.1105, -0.1356, -0.0947, -0.0672, -0.0459, -0.0397]],\n",
            "       grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0KfPFk1B5d7",
        "colab_type": "text"
      },
      "source": [
        "# preparing for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPDUsxWqB6So",
        "colab_type": "code",
        "outputId": "a617de05-74bf-4483-ec3d-c22f0083bdb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "import random\n",
        "\n",
        "#netowrk interpreter - guess category based on network output\n",
        "def category_guess(output):\n",
        "  n, i = output.topk(1)\n",
        "  category_index = i.item()\n",
        "  return all_categories[category_index], category_index\n",
        "\n",
        "print(category_guess(output))\n",
        "\n",
        "#generate a training example\n",
        "def random_choice(x):\n",
        "  return x[random.randint(0,len(x)-1)]\n",
        "\n",
        "def random_example():\n",
        "  r_cat = random_choice(all_categories)\n",
        "  r_line = random_choice(category_lines[r_cat])\n",
        "  category_tensor = torch.tensor([all_categories.index(r_cat)], dtype=torch.long)\n",
        "  line_tensor = line_to_tensor(r_line)\n",
        "  return r_cat, r_line, category_tensor, line_to_tensor\n",
        "\n",
        "for i in range(10):\n",
        "    r_cat, r_line, category_tensor, line_tensor = random_example()\n",
        "    print('category =', r_cat, '/ line =', r_line)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Portuguese', 17)\n",
            "category = Scottish / line = Mccallum\n",
            "category = Chinese / line = Huang\n",
            "category = Arabic / line = Tuma\n",
            "category = Vietnamese / line = Ma\n",
            "category = Greek / line = Zaloumi\n",
            "category = Italian / line = Abatescianni\n",
            "category = Arabic / line = Hakimi\n",
            "category = Vietnamese / line = Han\n",
            "category = Spanish / line = Quintana\n",
            "category = Arabic / line = Almasi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjF38strxbjP",
        "colab_type": "text"
      },
      "source": [
        "# training the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfp8-UP5tLrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set up the training function\n",
        "learning_rate = .005\n",
        "\n",
        "def train(category_tensor, line_tensor):\n",
        "  hidden = rnn.init_hidden()\n",
        "  rnn.zero_grad()\n",
        "  \n",
        "  for i in range(line_tensor.size()[0]):\n",
        "    output, hidden = rnn(line_tensor[i], hidden)\n",
        "\n",
        "  loss = nn.NLLLoss(output, category_tensor)\n",
        "  loss.backward()\n",
        "\n",
        "  for p in rnn.parameters():\n",
        "    p.data.add_(-learning_rate, p.grad.data))\n",
        "\n",
        "  return output, loss.item()\n",
        "\n",
        "#train the network\n",
        "import time\n",
        "import math\n",
        "\n",
        "n_iters = 100000\n",
        "print_every = 5000\n",
        "plot_every = 1000\n",
        "\n",
        "current_loss = 0\n",
        "all_losses = []\n",
        "\n",
        "def time(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "start = start.time()\n",
        "\n",
        "for i in range(1,n_iters+1):\n",
        "  r_cat, r_line, category_tensor, line_tensor = random_example()\n",
        "  output, loss = train(category_tensor, line_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}